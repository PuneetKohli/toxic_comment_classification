{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from score import calc_auc_score, calc_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read files\n",
    "def readInputFiles(train_file_path, test_file_path):\n",
    "    train = pd.read_csv(train_file_path)\n",
    "    test = pd.read_csv(test_file_path)\n",
    "    train = train.sample(frac=1)\n",
    "    return train, test\n",
    "    \n",
    "train, test = readInputFiles('../dataset/train_new.csv', '../dataset/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../embeddings/crawl-300d-2M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e8bd3575-f711-4ca6-a653-8ec1c74c0204",
    "_uuid": "cf43ac37cbd14d8baa088648c2275123550135d6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"comment_text\"].fillna(\"fillna\")\n",
    "test[\"comment_text\"].fillna(\"fillna\")\n",
    "X_train = train[\"comment_text\"].str.lower()\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "\n",
    "X_test = test[\"comment_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "da409613-3688-4d2e-a072-f67dee02617b",
    "_uuid": "efad6a0ecd758a759f14287a69bfd9cafa8c8fb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features=20000\n",
    "maxlen=200\n",
    "embed_size=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "3b0804b5-d64e-474e-8252-78daa4a4be62",
    "_uuid": "70c576f3b0afd3e779df184f788107fb51233424",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "7a665c08-b4a9-4792-b40b-481b3da907e5",
    "_uuid": "b07e998ccedaf3aaaf4b4e67b207ad5490eb24f7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok=text.Tokenizer(num_words=max_features,lower=True)\n",
    "tok.fit_on_texts(list(X_train)+list(X_test))\n",
    "X_train=tok.texts_to_sequences(X_train)\n",
    "X_test=tok.texts_to_sequences(X_test)\n",
    "x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n",
    "x_test=sequence.pad_sequences(X_test,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "9e57a7cb-c061-4361-bbe2-05c0486a3f18",
    "_uuid": "9488bc9d68dfd1fde1f99d23a9f1ed7b30ceb87f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE) as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "e2490100-fc9c-4e46-ae84-7dfa65fcddba",
    "_uuid": "d56ad119931a971b2588355deb726a045764c9ad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_index = tok.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "1a4a1cf3-7faf-4ee4-a72e-a258169778a5",
    "_uuid": "560d3faac051bbb95dae6f1bf7013d52b404533c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(maxlen, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool]) \n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "preds = Dense(6, activation=\"sigmoid\")(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "46df26aa-adcd-4b2c-8644-76a1e51df2bc",
    "_uuid": "19975febdf6a0bd3077d8a92da13bb433085ce80"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "e1962822-5dfb-4249-a714-ce95346150d4",
    "_uuid": "7956b05d34604689b7a10d56a61640091559eda2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepath=\"../input/best-model/best.hdf5\"\n",
    "filepath=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\n",
    "callbacks_list = [ra_val,checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "265115a8-296e-4b67-a6fc-02d0a584b501",
    "_uuid": "f7377e50952ffb6cc14bab3b34442788864eed68",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/2\n",
      "114890/114890 [==============================] - 1736s 15ms/step - loss: 0.0543 - acc: 0.9808 - val_loss: 0.0418 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.986959\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98439, saving model to weights_base.best.hdf5\n",
      "Epoch 2/2\n",
      "114890/114890 [==============================] - 1742s 15ms/step - loss: 0.0457 - acc: 0.9829 - val_loss: 0.0413 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988430\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.98439\n",
      "Predicting....\n",
      "31915/31915 [==============================] - 173s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),callbacks = callbacks_list,verbose=1)\n",
    "#Loading model weights\n",
    "model.load_weights(filepath)\n",
    "print('Predicting....')\n",
    "y_pred = model.predict(x_test,batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"bidirectional-gru-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# create the submission file and store the results\n",
    "def saveResults():\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for idx, col in enumerate(list_classes):\n",
    "        submission[col] = y_pred[:,idx]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "saveResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(test, preds, fallback_preds_filename):\n",
    "    try: \n",
    "        true = test\n",
    "    except NameError:\n",
    "        true = pd.read_csv('../dataset/test_new.csv')\n",
    "    try: \n",
    "        y_pred = preds\n",
    "    except NameError:\n",
    "        pred = pd.read_csv(fallback_preds_filename)\n",
    "        y_pred = pred[list_classes].values\n",
    "\n",
    "    y_true = true[list_classes].values\n",
    "\n",
    "    loss = calc_log_loss(y_true, y_pred)\n",
    "    auc = calc_auc_score(y_true, y_pred)\n",
    "    return loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = pd.read_csv('../dataset/test_new.csv')\n",
    "pred = y_pred\n",
    "\n",
    "loss_, aucs = get_scores(true, y_pred, fallback_preds_filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log loss = ', 0.0439968395945281)\n",
      "('AUC Score = ', 0.9856054410896794)\n"
     ]
    }
   ],
   "source": [
    "print (\"Log loss = \", loss_)\n",
    "print (\"AUC Score = \", aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace GRU with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input2 = Input(shape=(maxlen, ))\n",
    "x2 = Embedding(max_features, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input2)\n",
    "x2 = SpatialDropout1D(0.2)(x2)\n",
    "x2 = Bidirectional(LSTM(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x2)\n",
    "x2 = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x2)\n",
    "avg_pool = GlobalAveragePooling1D()(x2)\n",
    "max_pool = GlobalMaxPooling1D()(x2)\n",
    "x2 = concatenate([avg_pool, max_pool]) \n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "preds2 = Dense(6, activation=\"sigmoid\")(x2)\n",
    "model2 = Model(sequence_input2, preds2)\n",
    "model2.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights_base_lstm.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5)\n",
    "ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\n",
    "callbacks_list = [ra_val,checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/2\n",
      "114890/114890 [==============================] - 2197s 19ms/step - loss: 0.0547 - acc: 0.9807 - val_loss: 0.0433 - val_acc: 0.9839\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.984814\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.98392, saving model to weights_base_lstm.best.hdf5\n",
      "Epoch 2/2\n",
      "104960/114890 [==========================>...] - ETA: 3:17 - loss: 0.0446 - acc: 0.9834"
     ]
    }
   ],
   "source": [
    "model2.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),callbacks = callbacks_list,verbose=1)\n",
    "#Loading model weights\n",
    "model2.load_weights(filepath)\n",
    "print('Predicting....')\n",
    "y_pred2 = model2.predict(x_test,batch_size=1024,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
