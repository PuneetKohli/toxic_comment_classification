{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "import re, string\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from score import calc_auc_score, calc_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def readInputFiles(train_file_path, test_file_path):\n",
    "    train = pd.read_csv(train_file_path)\n",
    "    test = pd.read_csv(test_file_path)\n",
    "    return train, test\n",
    "    \n",
    "train, test = readInputFiles('../dataset/train_new.csv', '../dataset/test_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.00000</td>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.000000</td>\n",
       "      <td>127656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79621.481724</td>\n",
       "      <td>0.095867</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>0.052751</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.898313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46090.149802</td>\n",
       "      <td>0.294410</td>\n",
       "      <td>0.09940</td>\n",
       "      <td>0.223537</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.215997</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.302238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39654.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79641.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119511.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159569.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic  severe_toxic        obscene  \\\n",
       "count  127656.000000  127656.000000  127656.00000  127656.000000   \n",
       "mean    79621.481724       0.095867       0.00998       0.052751   \n",
       "std     46090.149802       0.294410       0.09940       0.223537   \n",
       "min         1.000000       0.000000       0.00000       0.000000   \n",
       "25%     39654.750000       0.000000       0.00000       0.000000   \n",
       "50%     79641.000000       0.000000       0.00000       0.000000   \n",
       "75%    119511.500000       0.000000       0.00000       0.000000   \n",
       "max    159569.000000       1.000000       1.00000       1.000000   \n",
       "\n",
       "              threat         insult  identity_hate           none  \n",
       "count  127656.000000  127656.000000  127656.000000  127656.000000  \n",
       "mean        0.003165       0.049062       0.008703       0.898313  \n",
       "std         0.056167       0.215997       0.092884       0.302238  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preProcessData(trainData, testData):\n",
    "    # create a list of all the labels to predict\n",
    "    label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    # create a 'none' label so we can see how many comments have no labels\n",
    "    train['none'] = 1-train[label_cols].max(axis=1)\n",
    "    \n",
    "    # get rid of the empty comments, otherwise sklearn complains\n",
    "    COMMENT = 'comment_text'\n",
    "    train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    test[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    return label_cols\n",
    "\n",
    "label_cols = preProcessData(train, test)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_comments_train: 127656, n_features: 6643\n",
      "n_comments_test: 31915, n_features: 6643\n"
     ]
    }
   ],
   "source": [
    "def tokenize(s): \n",
    "    re_tok = re.compile('([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "    return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "# create bag of words representation, as a term document matrix using ngrams\n",
    "def wordRepresentation(trainData, testData):\n",
    "    # TF-IDF gives even better priors than the binarized features. \n",
    "    # it improves leaderboard score from 0.59 to 0.55.\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1, analyzer='char')\n",
    "\n",
    "    COMMENT = 'comment_text'\n",
    "    \n",
    "    # Extracting features from the training data using a sparse vectorizer\"\n",
    "    train_term_doc = vec.fit_transform(trainData[COMMENT])\n",
    "\n",
    "    # Extracting features from the test data using the same vectorizer\n",
    "    test_term_doc = vec.transform(testData[COMMENT])\n",
    "\n",
    "    # a sparse matrix with only a small number of non-zero elements with the below shape\n",
    "    print(\"n_comments_train: %d, n_features: %d\" % train_term_doc.shape)\n",
    "    print(\"n_comments_test: %d, n_features: %d\" % test_term_doc.shape)\n",
    "    \n",
    "    return train_term_doc, test_term_doc, vec\n",
    "    \n",
    "train_term_doc, test_term_doc, vec = wordRepresentation(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fitting', 'toxic')\n",
      "('fitting', 'severe_toxic')\n",
      "('fitting', 'obscene')\n",
      "('fitting', 'threat')\n",
      "('fitting', 'insult')\n",
      "('fitting', 'identity_hate')\n"
     ]
    }
   ],
   "source": [
    "# fit model and make predictions\n",
    "def getPredictions(test, label_cols):\n",
    "    \n",
    "    model_r_dict = {}\n",
    "    \n",
    "    preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "    for i, j in enumerate(label_cols):\n",
    "        print('fitting', j)\n",
    "        m,r = get_mdl(train[j])\n",
    "        \n",
    "        # store model and r value for future predictions\n",
    "        model_r_dict[i] = r, m \n",
    "        \n",
    "        # get predictions\n",
    "        preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
    "\n",
    "    return preds, model_r_dict\n",
    "    \n",
    "preds, model_r_dict = getPredictions(test, label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = joblib.dump(model_r_dict, \"baseline_nb_svm_char_ngrams.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_new = nbsvm.get_preds_from_model(joblib.load(\"baseline_nb_svm_char_ngrams.pkl\"), test_x, label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the submission file and store the results\n",
    "def saveResults():\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for idx, col in enumerate(label_cols):\n",
    "        submission[col] = predictions[:,idx]\n",
    "    submission.to_csv('submission_char_ngrams_new.csv', index=False)\n",
    "    \n",
    "saveResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log Loss = ', 0.07261229076372638)\n",
      "('AUC = ', 0.9494655609891954)\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    true = test\n",
    "except NameError:\n",
    "    true = pd.read_csv('../dataset/test_new.csv')\n",
    "try: \n",
    "    pred = preds\n",
    "except NameError:\n",
    "    pred = pd.read_csv('submission_char_ngrams_new.csv')\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_true = true[list_classes].values\n",
    "y_pred = pred[list_classes].values\n",
    "\n",
    "loss = calc_log_loss(y_true, y_pred)\n",
    "print (\"Log Loss = \", loss)\n",
    "auc = calc_auc_score(y_true, y_pred)\n",
    "print (\"AUC = \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nbsvm' from 'nbsvm.py'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nbsvm\n",
    "reload (nbsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbsvm.train_model(train, test_x, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
