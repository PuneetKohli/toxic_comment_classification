{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d3b04218-0413-4e6c-8751-5d8a404d73a9",
    "_uuid": "0bca9739b82d5d51e1229243e03ea1b6db35c17e"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline. In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4",
    "_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re, string\n",
    "from sklearn.externals import joblib\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from score import calc_auc_score, calc_log_loss\n",
    "import nbsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a494f561-0c2f-4a38-8973-6b60c22da357",
    "_uuid": "f70ebe669fcf6b434c595cf6fb7a76120bf7809c"
   },
   "source": [
    "## Take Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a494f561-0c2f-4a38-8973-6b60c22da357",
    "_uuid": "f70ebe669fcf6b434c595cf6fb7a76120bf7809c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the train and test data\n",
    "def readInputFiles(train_file_path, test_file_path):\n",
    "    train = pd.read_csv(train_file_path)\n",
    "    test = pd.read_csv(test_file_path)\n",
    "    return train, test\n",
    "    \n",
    "train, test = readInputFiles('../dataset/train_new.csv', '../dataset/test_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b8515824-b2dd-4c95-bbf9-dc74c80355db",
    "_uuid": "0151ab55887071aed82d297acb2c6545ed964c2b"
   },
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "c66f79d1-1d9f-4d94-82c1-8026af198f2a",
    "_uuid": "4ba6ef86c82f073bf411785d971a694348c3efa9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140030</td>\n",
       "      <td>ed56f082116dcbd0</td>\n",
       "      <td>Grandma Terri Should Burn in Trash \\nGrandma T...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159124</td>\n",
       "      <td>f8e3cd98b63bf401</td>\n",
       "      <td>, 9 May 2009 (UTC)\\nIt would be easiest if you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60006</td>\n",
       "      <td>a09e1bcf10631f9a</td>\n",
       "      <td>\"\\n\\nThe Objectivity of this Discussion is dou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65432</td>\n",
       "      <td>af0ee0066c607eb8</td>\n",
       "      <td>Shelly Shock\\nShelly Shock is. . .( )</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154979</td>\n",
       "      <td>b734772b1a807e09</td>\n",
       "      <td>I do not care. Refer to Ong Teng Cheong talk p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  \\\n",
       "0      140030  ed56f082116dcbd0   \n",
       "1      159124  f8e3cd98b63bf401   \n",
       "2       60006  a09e1bcf10631f9a   \n",
       "3       65432  af0ee0066c607eb8   \n",
       "4      154979  b734772b1a807e09   \n",
       "\n",
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Grandma Terri Should Burn in Trash \\nGrandma T...      1             0   \n",
       "1  , 9 May 2009 (UTC)\\nIt would be easiest if you...      0             0   \n",
       "2  \"\\n\\nThe Objectivity of this Discussion is dou...      0             0   \n",
       "3              Shelly Shock\\nShelly Shock is. . .( )      0             0   \n",
       "4  I do not care. Refer to Ong Teng Cheong talk p...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  none  \n",
       "0        0       0       0              0     0  \n",
       "1        0       0       0              0     1  \n",
       "2        0       0       0              0     1  \n",
       "3        0       0       0              0     1  \n",
       "4        0       0       0              0     1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMENT = 'comment_text'\n",
    "\n",
    "def preProcessData(trainData, testData):\n",
    "    # create a list of all the labels to predict\n",
    "    label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    # create a 'none' label so we can see how many comments have no labels\n",
    "    train['none'] = 1-train[label_cols].max(axis=1)\n",
    "    \n",
    "    train.describe()\n",
    "    \n",
    "    # get rid of the empty comments, otherwise sklearn complains\n",
    "    train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    test[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "    return label_cols\n",
    "\n",
    "label_cols = preProcessData(train, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "480780f1-00c0-4f9a-81e5-fc1932516a80",
    "_uuid": "f2e77e8e6df5e29b620c7a2a0add1438c35af932"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b7f11db7-5c12-4eb8-9f2d-0323d629fed9",
    "_uuid": "b043a3fb66c443fab0129e863c134ec813dadb87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_comments_train: 127656, n_features: 64631\n",
      "n_comments_test: 31915, n_features: 64631\n"
     ]
    }
   ],
   "source": [
    "def tokenize(s): \n",
    "    re_tok = re.compile('([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "    return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "# create bag of words representation, as a term document matrix using ngrams\n",
    "def wordRepresentation(trainData, testData):\n",
    "    # TF-IDF gives even better priors than the binarized features. \n",
    "    # it improves leaderboard score from 0.59 to 0.55.\n",
    "    \n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "                   min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "                   smooth_idf=1, sublinear_tf=1 )\n",
    "    \n",
    "      # Extracting features from the training data using a sparse vectorizer\"\n",
    "    train_term_doc = vec.fit_transform(trainData[COMMENT])\n",
    "\n",
    "    # Extracting features from the test data using the same vectorizer\n",
    "    test_term_doc = vec.transform(testData[COMMENT])\n",
    "\n",
    "    # a sparse matrix with only a small number of non-zero elements with the below shape\n",
    "    print(\"n_comments_train: %d, n_features: %d\" % train_term_doc.shape)\n",
    "    print(\"n_comments_test: %d, n_features: %d\" % test_term_doc.shape)\n",
    "    \n",
    "    return train_term_doc, test_term_doc, vec\n",
    "    \n",
    "train_term_doc, test_term_doc, vec = wordRepresentation(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59131479-a861-4f46-add9-b2af09a51976",
    "_uuid": "5fc487461f4c6fdaea25f2cd471fc801856c6689"
   },
   "source": [
    "## Basic Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fitting', 'toxic')\n",
      "('fitting', 'severe_toxic')\n",
      "('fitting', 'obscene')\n",
      "('fitting', 'threat')\n",
      "('fitting', 'insult')\n",
      "('fitting', 'identity_hate')\n",
      "{0: (matrix([[ 0.79319337,  1.10221879, -0.04566331, ...,  0.9486203 ,\n",
      "          2.67195444,  1.66506689]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), 1: (matrix([[0.99188468, 3.45464817, 0.57473657, ..., 3.30104969, 4.23525492,\n",
      "         4.01749628]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), 2: (matrix([[0.78087074, 2.01754999, 0.10412072, ..., 1.59251506, 2.52672029,\n",
      "         2.30896164]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), 3: (matrix([[1.03152116, 4.60832282, 1.50804853, ..., 4.45472433, 5.14405696,\n",
      "         5.17117092]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), 4: (matrix([[0.78741718, 1.82249987, 0.10568181, ..., 1.66890139, 2.60310661,\n",
      "         2.38534797]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), 5: (matrix([[0.73978375, 3.59272306, 0.55598717, ..., 3.43912457, 3.80259248,\n",
      "         4.15557116]]), LogisticRegression(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))}\n"
     ]
    }
   ],
   "source": [
    "model = nbsvm.train_model(train, train_x, label_cols, \"baseline_nb_svm_2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict from the created model, or load it from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = joblib.load(\"baseline_nb_svm.pkl\")\n",
    "preds = nbsvm.get_preds_from_model(mdl, test_x, label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the submission file and store the results\n",
    "def saveResults(predictions):\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for idx, col in enumerate(label_cols):\n",
    "        submission[col] = predictions[:,idx]\n",
    "    submission.to_csv('submission_baseline_2.csv', index=False)\n",
    "    \n",
    "saveResults(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Log loss / AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "try: \n",
    "    true = test\n",
    "except NameError:\n",
    "    true = pd.read_csv('../dataset/test_new.csv')\n",
    "try: \n",
    "    y_pred = preds\n",
    "except NameError:\n",
    "    pred = pd.read_csv('submission_baseline.csv')\n",
    "    y_pred = pred[list_classes].values\n",
    "\n",
    "y_true = true[list_classes].values\n",
    "\n",
    "loss = calc_log_loss(y_true, y_pred)\n",
    "print (\"Log Loss = \", loss)\n",
    "auc = calc_auc_score(y_true, y_pred)\n",
    "print (\"AUC = \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a comment: \"jews are nice\"\n",
      "\n",
      "      toxic severe_toxic    obscene      threat     insult identity_hate\n",
      "0  0.285182   0.00320251  0.0269435  0.00446865  0.0429508      0.858546\n"
     ]
    }
   ],
   "source": [
    "# for demo purposes only\n",
    "def demo(vectorizer, label_cols, mdl):\n",
    "    testing_comment = input(\"Enter a comment: \")\n",
    "\n",
    "    # testing_comment = [\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.\"]\n",
    "\n",
    "    # vectorizer.transform takes list input so pass a list\n",
    "    user_comment = []\n",
    "    user_comment.append(testing_comment)\n",
    "    \n",
    "    # Extracting features from the test data using the vectorizer\n",
    "    test_data_x = vectorizer.transform(user_comment)\n",
    "    \n",
    "    # to store the predictions\n",
    "    prediction = np.zeros((1, len(label_cols)))\n",
    "\n",
    "    # make prediction using the model created\n",
    "    for i, j in enumerate(label_cols):\n",
    "        r = mdl[i][0]\n",
    "        m = mdl[i][1]\n",
    "        prediction[0,i] = m.predict_proba(test_data_x.multiply(r))[0,1]\n",
    "    \n",
    "    # copy the result and display\n",
    "    pred_y = pd.DataFrame(columns=label_cols)\n",
    "    for idx, col in enumerate(label_cols):\n",
    "        pred_y.at[0, col] = prediction[0,idx]  \n",
    "     \n",
    "    print (\"\")\n",
    "    print (pred_y)\n",
    "#     # The String I used above is for the first comment, that is, result of loc 0 in submission file\n",
    "#     print (\"This is the actual result: \", submission.loc[0])\n",
    "\n",
    "demo(vec, label_cols, mdl)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
