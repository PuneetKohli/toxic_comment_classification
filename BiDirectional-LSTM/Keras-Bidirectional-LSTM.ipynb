{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from subprocess import check_output\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from score import calc_auc_score, calc_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read files\n",
    "def readInputFiles(train_file_path, test_file_path):\n",
    "    train = pd.read_csv(train_file_path)\n",
    "    test = pd.read_csv(test_file_path)\n",
    "    train = train.sample(frac=1)\n",
    "    return train, test\n",
    "    \n",
    "train, test = readInputFiles('../dataset/train_new.csv', '../dataset/test_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessData():\n",
    "    max_features = 20000\n",
    "    maxlen = 100\n",
    "\n",
    "    # grab all the comments from train and fill the NAN comments with CVxTz\n",
    "    list_sentences_train = train[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "\n",
    "    # get the values for 6 classes\n",
    "    list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "    y = train[list_classes].values\n",
    "\n",
    "    # grab all the comments from test and fill the NAN comments with CVxTz\n",
    "    list_sentences_test = test[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "\n",
    "    tokenizer = text.Tokenizer(num_words=max_features)\n",
    "\n",
    "    # only use the training data comments for tokenizer\n",
    "    tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "\n",
    "    # convert form strings to list of indices of words\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "\n",
    "    # truncate list if length over 100\n",
    "    # pad list if length less than 100\n",
    "    X_train = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "    X_test = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "    \n",
    "    return max_features, maxlen, X_train, X_test, y\n",
    "    \n",
    "max_features, maxlen, X_train, X_test, y = preProcessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# configure a model\n",
    "def get_model():\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/2\n",
      "114890/114890 [==============================] - 747s 7ms/step - loss: 0.0682 - acc: 0.9776 - val_loss: 0.0488 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04880, saving model to weights_base.best.hdf5\n",
      "Epoch 2/2\n",
      "114890/114890 [==============================] - 705s 6ms/step - loss: 0.0469 - acc: 0.9828 - val_loss: 0.0471 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04880 to 0.04709, saving model to weights_base.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "\n",
    "def createModel(file_path):\n",
    "    model = get_model()\n",
    "    batch_size = 32\n",
    "    epochs = 2\n",
    "\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "    # The point is to let the script run for more epochs locally \n",
    "    # because it will timeout if done so in Kaggle Kernels\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "    callbacks_list = [checkpoint, early] #early\n",
    "    model.fit(X_train, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
    "\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    return model\n",
    "print \"done\"\n",
    "    \n",
    "# file_path: file where model gets stored\n",
    "model = createModel(\"weights_base.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"bidirectional_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# create the submission file and store the results\n",
    "def saveResults():\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for idx, col in enumerate(list_classes):\n",
    "        submission[col] = predictions[:,idx]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "saveResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(test, preds, fallback_preds_filename):\n",
    "    try: \n",
    "        true = test\n",
    "    except NameError:\n",
    "        true = pd.read_csv('../dataset/test_new.csv')\n",
    "    try: \n",
    "        y_pred = preds\n",
    "    except NameError:\n",
    "        pred = pd.read_csv(fallback_preds_filename)\n",
    "        y_pred = pred[list_classes].values\n",
    "\n",
    "    y_true = true[list_classes].values\n",
    "\n",
    "    loss = calc_log_loss(y_true, y_pred)\n",
    "    auc = calc_auc_score(y_true, y_pred)\n",
    "    return loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n",
      "[0.18822935 0.00020282 0.00796122 0.0015497  0.01676907 0.00307044]\n"
     ]
    }
   ],
   "source": [
    "true = pd.read_csv('../dataset/test_new.csv')\n",
    "pred = predictions\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_true = true[list_classes].values\n",
    "\n",
    "print y_true[0]\n",
    "print predictions[0]\n",
    "loss_, aucs = get_scores(true, pred, fallback_preds_filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log loss = ', 0.04911418352106683)\n",
      "('AUC Score = ', 0.9761352698716607)\n"
     ]
    }
   ],
   "source": [
    "print (\"Log loss = \", loss_)\n",
    "print (\"AUC Score = \", aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
