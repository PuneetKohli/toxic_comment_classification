{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/user/achadha7/.conda/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiots</th>\n",
       "      <th>awful</th>\n",
       "      <th>stupid</th>\n",
       "      <th>hell</th>\n",
       "      <th>abortion</th>\n",
       "      <th>worst</th>\n",
       "      <th>moron</th>\n",
       "      <th>screw</th>\n",
       "      <th>terrible</th>\n",
       "      <th>suck</th>\n",
       "      <th>...</th>\n",
       "      <th>sexist</th>\n",
       "      <th>supremacists</th>\n",
       "      <th>assholes</th>\n",
       "      <th>ignorant</th>\n",
       "      <th>morons</th>\n",
       "      <th>nationalists</th>\n",
       "      <th>rubbish</th>\n",
       "      <th>ass</th>\n",
       "      <th>uneducated</th>\n",
       "      <th>idiot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i,,,diioots</td>\n",
       "      <td>ÄWfu\\\\l</td>\n",
       "      <td>5tup1D</td>\n",
       "      <td>HE|l</td>\n",
       "      <td>aabórt~~~ioN</td>\n",
       "      <td>wo.RSt</td>\n",
       "      <td>M0RoÑ</td>\n",
       "      <td>sc~~~rrÉww</td>\n",
       "      <td>t,,Ë®rr:blle</td>\n",
       "      <td>$u¢k</td>\n",
       "      <td>...</td>\n",
       "      <td>5éXÎsst</td>\n",
       "      <td>SÙþRéMaac¡57ss</td>\n",
       "      <td>Áss5HOl??ËS</td>\n",
       "      <td>ì6Nõrån-t</td>\n",
       "      <td>M0®o¬¬¬n;;;s</td>\n",
       "      <td>nattioonâLi*s+5</td>\n",
       "      <td>Rú3BiSH</td>\n",
       "      <td>ãs**S</td>\n",
       "      <td>uñe\\dµca+eD</td>\n",
       "      <td>iDÌôT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ìDi¿¿oo+5</td>\n",
       "      <td>ÄWffùL</td>\n",
       "      <td>s7Úp\"\"\"i|D</td>\n",
       "      <td>hæLll</td>\n",
       "      <td>áb~oRt;;;i**o??n</td>\n",
       "      <td>wÒrstt</td>\n",
       "      <td>m,,0RÕN</td>\n",
       "      <td>sc..rrëw</td>\n",
       "      <td>têr:::RIbllê</td>\n",
       "      <td>Succk</td>\n",
       "      <td>...</td>\n",
       "      <td>$éXìstt</td>\n",
       "      <td>SuPremá{ïst$</td>\n",
       "      <td>Às5hôllÆ5</td>\n",
       "      <td>î6n_Ôr__Än~t</td>\n",
       "      <td>MÒrÒñS</td>\n",
       "      <td>Ñat^^|ooNa--lli==st==5</td>\n",
       "      <td>Ruþb?i\\\\s¬¬h</td>\n",
       "      <td>asss</td>\n",
       "      <td>unnÉdÜCÁtted</td>\n",
       "      <td>ÏdiÒ+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ÌDió7s</td>\n",
       "      <td>ªwFû¡</td>\n",
       "      <td>s::Tup!dd</td>\n",
       "      <td>hÊlll</td>\n",
       "      <td>ãbort¬¬íÖN</td>\n",
       "      <td>wÕrs==+</td>\n",
       "      <td>mmor|||0n</td>\n",
       "      <td>Sccr¨¨¨ÉW</td>\n",
       "      <td>TeRrÏb··llÈ</td>\n",
       "      <td>5u&lt;k</td>\n",
       "      <td>...</td>\n",
       "      <td>$ê*¡5+</td>\n",
       "      <td>5ùP®e¿¿¿m~~áCistS</td>\n",
       "      <td>á5shhoolè$</td>\n",
       "      <td>igNO®Ân..tt</td>\n",
       "      <td>MoR0ns</td>\n",
       "      <td>ña+i:ooña!i...s+S</td>\n",
       "      <td>r\"\"úbßi~~5#</td>\n",
       "      <td>as\\5</td>\n",
       "      <td>u//Ne;;;du,,&lt;ate||d</td>\n",
       "      <td>îDiÔt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ïD¡o\\\\\\+S</td>\n",
       "      <td>aawwfù!</td>\n",
       "      <td>s7ÚpÍdd</td>\n",
       "      <td>hël|</td>\n",
       "      <td>Æbört¿¿¿i\"\"\"öN</td>\n",
       "      <td>Wo^^^rr5+</td>\n",
       "      <td>m???o\"rooñ</td>\n",
       "      <td>s{Rew</td>\n",
       "      <td>Te:rRiþLè</td>\n",
       "      <td>sµc::k</td>\n",
       "      <td>...</td>\n",
       "      <td>$e%i???st</td>\n",
       "      <td>$up;;®ém__a©Ìss7s</td>\n",
       "      <td>a*ss#ool::è5</td>\n",
       "      <td>iggn0Råñt</td>\n",
       "      <td>m ör--Óñ5</td>\n",
       "      <td>n¨¨at-!ONâ£i¨¨¨s+5</td>\n",
       "      <td>ruBþi?5h</td>\n",
       "      <td>å5s</td>\n",
       "      <td>une¨du¬CaatÉD</td>\n",
       "      <td>i\\di0tt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i¨¨¨d¨¨íOtss</td>\n",
       "      <td>awFuu£</td>\n",
       "      <td>st__üpÏdd</td>\n",
       "      <td>hel?!</td>\n",
       "      <td>aßÕRTÏoon</td>\n",
       "      <td>w\"\"\"or\\s¬+</td>\n",
       "      <td>MóròÑ</td>\n",
       "      <td>scr3w</td>\n",
       "      <td>7e===rrr1bbllæ</td>\n",
       "      <td>ssÜcK</td>\n",
       "      <td>...</td>\n",
       "      <td>s¬¬ÈX!ssT</td>\n",
       "      <td>supremácìsts</td>\n",
       "      <td>a55holÉS</td>\n",
       "      <td>!GNo¨¨r___añ+</td>\n",
       "      <td>µo--Roñ$</td>\n",
       "      <td>natïÖñÄ¡i  sst\"\"\"S</td>\n",
       "      <td>rrü83ish</td>\n",
       "      <td>àS5</td>\n",
       "      <td>Vne??Ducättëd</td>\n",
       "      <td>ÎDÌo..t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ìdi'''ôTs</td>\n",
       "      <td>awfu!</td>\n",
       "      <td>stuupID</td>\n",
       "      <td>#ë¡L</td>\n",
       "      <td>âþo?Rtion</td>\n",
       "      <td>wO®s...T</td>\n",
       "      <td>MÔroon</td>\n",
       "      <td>sc..rre;w</td>\n",
       "      <td>te_rRibl~~Ë</td>\n",
       "      <td>5Vþk</td>\n",
       "      <td>...</td>\n",
       "      <td>$e¬¬xIsT</td>\n",
       "      <td>Su..p//r¿¿¿ema·cÎ5tts</td>\n",
       "      <td>â$ShO¡eeS</td>\n",
       "      <td>:6ÑºrÄñ7</td>\n",
       "      <td>µo~~r''o'''n\"\"\"5</td>\n",
       "      <td>nna^^^+i¿¿¿o;;;näll|s\\T5</td>\n",
       "      <td>r???Vb???bbi¬SH</td>\n",
       "      <td>as_5</td>\n",
       "      <td>ûNed**uca===+Éd</td>\n",
       "      <td>idiiOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Id^^:ôt$</td>\n",
       "      <td>a_w,,Fü/</td>\n",
       "      <td>sstvpiD</td>\n",
       "      <td>He__lL</td>\n",
       "      <td>ÂböRTîon</td>\n",
       "      <td>wwÒr?s::T</td>\n",
       "      <td>m,o|||ron</td>\n",
       "      <td>ss¢RÉw</td>\n",
       "      <td>+È®RÎb¡ee</td>\n",
       "      <td>s··uucK</td>\n",
       "      <td>...</td>\n",
       "      <td>5e*i***st</td>\n",
       "      <td>5ÙþrÆMa\"\"Çí$+5</td>\n",
       "      <td>Á5SHoolee5</td>\n",
       "      <td>i···GNOraÑt</td>\n",
       "      <td>m**oRóÑs</td>\n",
       "      <td>ÑaattÎoNa---¡iis¬¬T$</td>\n",
       "      <td>r'Ùb6îsH</td>\n",
       "      <td>ås\"\"\"s</td>\n",
       "      <td>UnÉdÙ{AtÉD</td>\n",
       "      <td>ÎDi·o//+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idiots     awful      stupid    hell          abortion       worst  \\\n",
       "0   i,,,diioots   ÄWfu\\\\l      5tup1D    HE|l      aabórt~~~ioN      wo.RSt   \n",
       "1     ìDi¿¿oo+5    ÄWffùL  s7Úp\"\"\"i|D   hæLll  áb~oRt;;;i**o??n      wÒrstt   \n",
       "2        ÌDió7s     ªwFû¡   s::Tup!dd   hÊlll        ãbort¬¬íÖN     wÕrs==+   \n",
       "3     ïD¡o\\\\\\+S   aawwfù!     s7ÚpÍdd    hël|    Æbört¿¿¿i\"\"\"öN   Wo^^^rr5+   \n",
       "4  i¨¨¨d¨¨íOtss    awFuu£   st__üpÏdd   hel?!         aßÕRTÏoon  w\"\"\"or\\s¬+   \n",
       "5     Ìdi'''ôTs     awfu!     stuupID    #ë¡L         âþo?Rtion    wO®s...T   \n",
       "6      Id^^:ôt$  a_w,,Fü/     sstvpiD  He__lL          ÂböRTîon   wwÒr?s::T   \n",
       "\n",
       "        moron       screw        terrible     suck    ...        sexist  \\\n",
       "0       M0RoÑ  sc~~~rrÉww    t,,Ë®rr:blle     $u¢k    ...       5éXÎsst   \n",
       "1     m,,0RÕN    sc..rrëw    têr:::RIbllê    Succk    ...       $éXìstt   \n",
       "2   mmor|||0n   Sccr¨¨¨ÉW     TeRrÏb··llÈ     5u<k    ...        $ê*¡5+   \n",
       "3  m???o\"rooñ       s{Rew       Te:rRiþLè   sµc::k    ...     $e%i???st   \n",
       "4       MóròÑ       scr3w  7e===rrr1bbllæ    ssÜcK    ...     s¬¬ÈX!ssT   \n",
       "5      MÔroon   sc..rre;w     te_rRibl~~Ë     5Vþk    ...      $e¬¬xIsT   \n",
       "6   m,o|||ron      ss¢RÉw       +È®RÎb¡ee  s··uucK    ...     5e*i***st   \n",
       "\n",
       "            supremacists      assholes       ignorant            morons  \\\n",
       "0         SÙþRéMaac¡57ss   Áss5HOl??ËS      ì6Nõrån-t      M0®o¬¬¬n;;;s   \n",
       "1           SuPremá{ïst$     Às5hôllÆ5   î6n_Ôr__Än~t            MÒrÒñS   \n",
       "2      5ùP®e¿¿¿m~~áCistS    á5shhoolè$    igNO®Ân..tt            MoR0ns   \n",
       "3      $up;;®ém__a©Ìss7s  a*ss#ool::è5      iggn0Råñt         m ör--Óñ5   \n",
       "4           supremácìsts      a55holÉS  !GNo¨¨r___añ+          µo--Roñ$   \n",
       "5  Su..p//r¿¿¿ema·cÎ5tts     â$ShO¡eeS       :6ÑºrÄñ7  µo~~r''o'''n\"\"\"5   \n",
       "6         5ÙþrÆMa\"\"Çí$+5    Á5SHoolee5    i···GNOraÑt          m**oRóÑs   \n",
       "\n",
       "               nationalists          rubbish     ass           uneducated  \\\n",
       "0           nattioonâLi*s+5          Rú3BiSH   ãs**S          uñe\\dµca+eD   \n",
       "1    Ñat^^|ooNa--lli==st==5     Ruþb?i\\\\s¬¬h    asss         unnÉdÜCÁtted   \n",
       "2         ña+i:ooña!i...s+S      r\"\"úbßi~~5#    as\\5  u//Ne;;;du,,<ate||d   \n",
       "3        n¨¨at-!ONâ£i¨¨¨s+5         ruBþi?5h     å5s        une¨du¬CaatÉD   \n",
       "4        natïÖñÄ¡i  sst\"\"\"S         rrü83ish     àS5        Vne??Ducättëd   \n",
       "5  nna^^^+i¿¿¿o;;;näll|s\\T5  r???Vb???bbi¬SH    as_5      ûNed**uca===+Éd   \n",
       "6      ÑaattÎoNa---¡iis¬¬T$         r'Ùb6îsH  ås\"\"\"s           UnÉdÙ{AtÉD   \n",
       "\n",
       "      idiot  \n",
       "0     iDÌôT  \n",
       "1     ÏdiÒ+  \n",
       "2     îDiÔt  \n",
       "3   i\\di0tt  \n",
       "4   ÎDÌo..t  \n",
       "5    idiiOT  \n",
       "6  ÎDi·o//+  \n",
       "\n",
       "[7 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = './dataset/obfuscations.xlsx'\n",
    "dfs = pd.read_excel(file_name, sheet_name='Toxic triggers obfuscations').fillna(\"\")\n",
    "dfs.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTokenizer(object):\n",
    "    def process_text(self, text):\n",
    "        raise NotImplemented\n",
    "\n",
    "    def process(self, texts):\n",
    "        for text in texts:\n",
    "            yield self.process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_PATTERNS = {\n",
    "    ' american ':\n",
    "        [\n",
    "            'amerikan'\n",
    "        ],\n",
    "\n",
    "    ' adolf ':\n",
    "        [\n",
    "            'adolf'\n",
    "        ],\n",
    "\n",
    "\n",
    "    ' hitler ':\n",
    "        [\n",
    "            'hitler'\n",
    "        ],\n",
    "\n",
    "    ' fuck':\n",
    "        [\n",
    "            '(f)(u|[^a-z0-9 ])(c|[^a-z0-9 ])(k|[^a-z0-9 ])([^ ])*',\n",
    "            '(f)([^a-z]*)(u)([^a-z]*)(c)([^a-z]*)(k)',\n",
    "            ' f[!@#\\$%\\^\\&\\*]*u[!@#\\$%\\^&\\*]*k', 'f u u c',\n",
    "            '(f)(c|[^a-z ])(u|[^a-z ])(k)', r'f\\*',\n",
    "            'feck ', ' fux ', 'f\\*\\*', \n",
    "            'f\\-ing', 'f\\.u\\.', 'f###', ' fu ', 'f@ck', 'f u c k', 'f uck', 'f ck'\n",
    "        ],\n",
    "\n",
    "    ' ass ':\n",
    "        [\n",
    "            '[^a-z]ass ', '[^a-z]azz ', 'arrse', ' arse ', '@\\$\\$'\n",
    "                                                           '[^a-z]anus', ' a\\*s\\*s', '[^a-z]ass[^a-z ]',\n",
    "            'a[@#\\$%\\^&\\*][@#\\$%\\^&\\*]', '[^a-z]anal ', 'a s s'\n",
    "        ] + [re.escape(a) for a in list(dfs[\"ass\"].values)],\n",
    "\n",
    "    ' ass hole ':\n",
    "        [\n",
    "            ' a[s|z]*wipe', 'a[s|z]*[w]*h[o|0]+[l]*e', '@\\$\\$hole'\n",
    "        ],\n",
    "\n",
    "    ' bitch ':\n",
    "        [\n",
    "            'b[w]*i[t]*ch', 'b!tch',\n",
    "            'bi\\+ch', 'b!\\+ch', '(b)([^a-z]*)(i)([^a-z]*)(t)([^a-z]*)(c)([^a-z]*)(h)',\n",
    "            'biatch', 'bi\\*\\*h', 'bytch', 'b i t c h'\n",
    "        ],\n",
    "\n",
    "    ' bastard ':\n",
    "        [\n",
    "            'ba[s|z]+t[e|a]+rd'\n",
    "        ],\n",
    "\n",
    "    ' trans gender':\n",
    "        [\n",
    "            'transgender'\n",
    "        ],\n",
    "\n",
    "    ' gay ':\n",
    "        [\n",
    "            'gay'\n",
    "        ],\n",
    "\n",
    "    ' cock ':\n",
    "        [\n",
    "            '[^a-z]cock', 'c0ck', '[^a-z]cok ', 'c0k', '[^a-z]cok[^aeiou]', ' cawk',\n",
    "            '(c)([^a-z ])(o)([^a-z ]*)(c)([^a-z ]*)(k)', 'c o c k'\n",
    "        ],\n",
    "\n",
    "    ' dick ':\n",
    "        [\n",
    "            ' dick[^aeiou]', 'deek', 'd i c k'\n",
    "        ],\n",
    "\n",
    "    ' suck ':\n",
    "        [\n",
    "            'sucker', '(s)([^a-z ]*)(u)([^a-z ]*)(c)([^a-z ]*)(k)', 'sucks', '5uck', 's u c k'\n",
    "        ],\n",
    "\n",
    "    ' cunt ':\n",
    "        [\n",
    "            'cunt', 'c u n t'\n",
    "        ],\n",
    "\n",
    "    ' bull shit ':\n",
    "        [\n",
    "            'bullsh\\*t', 'bull\\$hit'\n",
    "        ],\n",
    "\n",
    "    ' homo sex ual':\n",
    "        [\n",
    "            'homosexual'\n",
    "        ],\n",
    "\n",
    "    ' jerk ':\n",
    "        [\n",
    "            'jerk'\n",
    "        ],\n",
    "\n",
    "    ' idiot ':\n",
    "        [\n",
    "            'i[d]+io[t]+', '(i)([^a-z ]*)(d)([^a-z ]*)(i)([^a-z ]*)(o)([^a-z ]*)(t)', 'idiots'\n",
    "                                                                                      'i d i o t'\n",
    "        ] + [re.escape(a) for a  in list(dfs[\"idiot\"].values)],\n",
    "\n",
    "    ' dumb ':\n",
    "        [\n",
    "            '(d)([^a-z ]*)(u)([^a-z ]*)(m)([^a-z ]*)(b)'\n",
    "        ],\n",
    "\n",
    "    ' shit ':\n",
    "        [\n",
    "            'shitty', '(s)([^a-z ]*)(h)([^a-z ]*)(i)([^a-z ]*)(t)', 'shite', '\\$hit', 's h i t'\n",
    "        ],\n",
    "\n",
    "    ' shit hole ':\n",
    "        [\n",
    "            'shythole'\n",
    "        ],\n",
    "\n",
    "    ' retard ':\n",
    "        [\n",
    "            'returd', 'retad', 'retard', 'wiktard', 'wikitud'\n",
    "        ],\n",
    "\n",
    "    ' rape ':\n",
    "        [\n",
    "            ' raped'\n",
    "        ],\n",
    "\n",
    "    ' dumb ass':\n",
    "        [\n",
    "            'dumbass', 'dubass'\n",
    "        ],\n",
    "\n",
    "    ' ass head':\n",
    "        [\n",
    "            'butthead'\n",
    "        ],\n",
    "\n",
    "    ' sex ':\n",
    "        [\n",
    "            'sexy', 's3x', 'sexuality'\n",
    "        ],\n",
    "\n",
    "\n",
    "    ' nigger ':\n",
    "        [\n",
    "            'nigger', 'ni[g]+a', ' nigr ', 'negrito', 'niguh', 'n3gr', 'n i g g e r'\n",
    "        ],\n",
    "\n",
    "    ' shut the fuck up':\n",
    "        [\n",
    "            'stfu'\n",
    "        ],\n",
    "\n",
    "    ' pussy ':\n",
    "        [\n",
    "            'pussy[^c]', 'pusy', 'pussi[^l]', 'pusses'\n",
    "        ],\n",
    "\n",
    "    ' faggot ':\n",
    "        [\n",
    "            'faggot', ' fa[g]+[s]*[^a-z ]', 'fagot', 'f a g g o t', 'faggit',\n",
    "            '(f)([^a-z ]*)(a)([^a-z ]*)([g]+)([^a-z ]*)(o)([^a-z ]*)(t)', 'fau[g]+ot', 'fae[g]+ot',\n",
    "        ],\n",
    "\n",
    "    ' mother fucker':\n",
    "        [\n",
    "            ' motha ', ' motha f', ' mother f', 'motherucker',\n",
    "        ],\n",
    "\n",
    "    ' whore ':\n",
    "        [\n",
    "            'wh\\*\\*\\*', 'w h o r e'\n",
    "        ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_PATTERNS['idiots'] = [re.escape(a) for a in list(dfs[\"idiots\"].values)]\n",
    "RE_PATTERNS['awful']  =  [re.escape(a) for a in list(dfs[\"awful\"].values)]\n",
    "RE_PATTERNS['stupid']  =  [re.escape(a) for a in list(dfs[\"stupid\"].values)]\n",
    "RE_PATTERNS['hell']  =  [re.escape(a) for a in list(dfs[\"hell\"].values)]\n",
    "RE_PATTERNS['abortion']  =  [re.escape(a) for a in list(dfs[\"abortion\"].values)]\n",
    "RE_PATTERNS['worst']  =  [re.escape(a) for a in list(dfs[\"worst\"].values)]\n",
    "RE_PATTERNS['moron']  =  [re.escape(a) for a in list(dfs[\"moron\"].values)]\n",
    "RE_PATTERNS['screw']  =  [re.escape(a) for a in list(dfs[\"screw\"].values)]\n",
    "RE_PATTERNS['terrible']  =  [re.escape(a) for a in list(dfs[\"terrible\"].values)]\n",
    "RE_PATTERNS['suck']  =  [re.escape(a) for a in list(dfs[\"suck\"].values)]\n",
    "RE_PATTERNS['shame']  =  [re.escape(a) for a in list(dfs[\"shame\"].values)]\n",
    "RE_PATTERNS['racist']  =  [re.escape(a) for a in list(dfs[\"racist \"].values)]\n",
    "RE_PATTERNS['supremacists']  =  [re.escape(a) for a in list(dfs[\"supremacists\"].values)]\n",
    "RE_PATTERNS['assholes']  =  [re.escape(a) for a in list(dfs[\"assholes\"].values)]\n",
    "RE_PATTERNS['ignorant']  =  [re.escape(a) for a in list(dfs[\"ignorant\"].values)]\n",
    "RE_PATTERNS['morons']  =  [re.escape(a) for a in list(dfs[\"morons\"].values)]\n",
    "RE_PATTERNS['nationalists']  =  [re.escape(a) for a in list(dfs[\"nationalists\"].values)]\n",
    "RE_PATTERNS['rubbish']  =  [re.escape(a) for a in list(dfs[\"rubbish\"].values)]\n",
    "# RE_PATTERNS['ass']  =  [re.escape(a) for a in list(dfs[\"ass\"].values)]\n",
    "RE_PATTERNS['uneducated']  = [re.escape(a) for a in list(dfs[\"uneducated\"].values)]\n",
    "#RE_PATTERNS['idiot']  =  [re.escape(a) for a in list(dfs[\"idiot\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_PATTERNS['idiots'] = list(dfs[\"idiots\"].values)\n",
    "RE_PATTERNS['awful']  = list(dfs[\"awful\"].values)\n",
    "RE_PATTERNS['stupid']  = list(dfs[\"stupid\"].values)\n",
    "RE_PATTERNS['hell']  = list(dfs[\"hell\"].values)\n",
    "RE_PATTERNS['abortion']  = list(dfs[\"abortion\"].values)\n",
    "RE_PATTERNS['worst']  = list(dfs[\"worst\"].values)\n",
    "RE_PATTERNS['moron']  = list(dfs[\"moron\"].values)\n",
    "RE_PATTERNS['screw']  = list(dfs[\"screw\"].values)\n",
    "RE_PATTERNS['terrible']  = list(dfs[\"terrible\"].values)\n",
    "RE_PATTERNS['suck']  = list(dfs[\"suck\"].values)\n",
    "RE_PATTERNS['shame']  = list(dfs[\"shame\"].values)\n",
    "RE_PATTERNS['racist']  = list(dfs[\"racist \"].values)\n",
    "RE_PATTERNS['supremacists']  = list(dfs[\"supremacists\"].values)\n",
    "RE_PATTERNS['assholes']  = list(dfs[\"assholes\"].values)\n",
    "RE_PATTERNS['ignorant']  = list(dfs[\"ignorant\"].values)\n",
    "RE_PATTERNS['morons']  = list(dfs[\"morons\"].values)\n",
    "RE_PATTERNS['nationalists']  = list(dfs[\"nationalists\"].values)\n",
    "RE_PATTERNS['rubbish']  = list(dfs[\"rubbish\"].values)\n",
    "# RE_PATTERNS['ass']  = list(dfs[\"ass\"].values)\n",
    "RE_PATTERNS['uneducated']  = [re.escape(a) for a in list(dfs[\"uneducated\"].values)]\n",
    "#RE_PATTERNS['idiot']  = list(dfs[\"idiot\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternTokenizer(BaseTokenizer):\n",
    "    def __init__(self, lower=True, initial_filters=r\"[^a-z0-9!@#\\$%\\^\\&\\*_\\-,\\.' ]\", patterns=RE_PATTERNS,\n",
    "                 remove_repetitions=True):\n",
    "        self.lower = lower\n",
    "        self.patterns = patterns\n",
    "        self.initial_filters = initial_filters\n",
    "        self.remove_repetitions = remove_repetitions\n",
    "\n",
    "    def process_text(self, text):\n",
    "        x = self._preprocess(text)\n",
    "        for target, patterns in self.patterns.items():\n",
    "            for pat in patterns:\n",
    "                x = re.sub(pat, target, x)\n",
    "        x = re.sub(r\"[^a-z' ]\", ' ', x)\n",
    "        return x.split()\n",
    "\n",
    "    def process_ds(self, ds):\n",
    "        ### ds = Data series\n",
    "\n",
    "        # lower\n",
    "        ds = copy.deepcopy(ds)\n",
    "        if self.lower:\n",
    "            ds = ds.str.lower()\n",
    "        # remove special chars\n",
    "        if self.initial_filters is not None:\n",
    "            ds = ds.str.replace(self.initial_filters, ' ')\n",
    "        # fuuuuck => fuck\n",
    "        if self.remove_repetitions:\n",
    "            pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL) \n",
    "            ds = ds.str.replace(pattern, r\"\\1\")\n",
    "\n",
    "        for target, patterns in self.patterns.items():\n",
    "            for pat in patterns:\n",
    "                ds = ds.str.replace(pat, target)\n",
    "\n",
    "        ds = ds.str.replace(r\"[^a-z' ]\", ' ')\n",
    "\n",
    "        return ds.str.split()\n",
    "\n",
    "    def _preprocess(self, text):\n",
    "        # lower\n",
    "        if self.lower:\n",
    "            text = text.lower()\n",
    "\n",
    "        # remove special chars\n",
    "        if self.initial_filters is not None:\n",
    "            text = re.sub(self.initial_filters, ' ', text)\n",
    "\n",
    "        # fuuuuck => fuck\n",
    "        if self.remove_repetitions:\n",
    "            pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
    "            text = pattern.sub(r\"\\1\", text)\n",
    "        return text\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(comment):\n",
    "   \n",
    "    tokenizer = PatternTokenizer()\n",
    "    d = {'comment_text': [comment]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return tokenizer.process_ds(df[\"comment_text\"]).str.join(sep=\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clean_comment(\"naziii asshole cunt face bittchh go fuuuck uaself u trannie hoe3 tra@mp poopieie basstarrrd f##k\")[0])\n",
    "print(clean_comment(\"nazi\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
